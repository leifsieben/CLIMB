# ==============================================================================
# Prototyping config for a 50/50 supervised/unsupervised mix
# ==============================================================================
model:
  hidden_size: 256
  num_hidden_layers: 6
  num_attention_heads: 8
  intermediate_size: 1024
  max_position_embeddings: 512
  hidden_dropout_prob: 0.1
  attention_probs_dropout_prob: 0.1
  use_flash_attention: false

training:
  num_epochs: 4
  batch_size: 32
  learning_rate: 5e-5
  warmup_steps: 100
  weight_decay: 0.01
  mlm_probability: 0.15
  logging_steps: 25
  save_steps: 250
  eval_steps: 0
